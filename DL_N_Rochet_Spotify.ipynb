{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de workflow Nicolas Rochet avec dataset Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# Dans ce problème, vous allez réaliser un clustering d'un jeu de données de chansons provenant du site de spotify afin de créer des **clusters de chansons** ayant des propriétés similaires.  \n",
    "# Optionnellement, vous pourrez tenter de vous servir de votre meilleur modèle pour créer un **système de recommandation** capable d'assigner une chanson non traitée aux 5 chansons les plus proches.\n",
    "\n",
    "# train data set\n",
    "train_data = pd.read_csv(\"https://filedn.eu/lefeldrXcsSFgCcgc48eaLY/datasets/clustering/spotify_dataset_full.csv\")\n",
    "# This data set don't have a test set. Don't forget to make one from training set !\n",
    "\n",
    "\n",
    "## 0 - Splitter les données avec la methode hold out\n",
    "#y=train_data[\"popularity\"]\n",
    "#X=train_data.drop(columns=[\"popularity\"])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train=train_data.drop(columns=[\"popularity\"])\n",
    "y=train_data[\"popularity\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop data inutiles\n",
    "\n",
    "X_train=X_train.drop(columns=[\"track\"])\n",
    "X_train=X_train.drop(columns=[\"uri\"])\n",
    "X_train=X_train.drop(columns=[\"artist\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodage des données catégorielles (decade) avec OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#valeurs_uniques = X_train['decade'].unique()\n",
    "\n",
    "#Sélection de la colonne à encoder\n",
    "column_to_encode = X_train[['decade']]\n",
    "#Encodage de la colonne avec OrdinalEncoder en spécifiant l'ordre\n",
    "order = [['60s','70s','80s','90s','00s','10s']]  # Spécifier l'ordre des catégories\n",
    "enc = OrdinalEncoder(categories=order)\n",
    "encoded_column = enc.fit_transform(column_to_encode)\n",
    "#Ajout de la colonne encodée au DataFrame original\n",
    "X_train['decade_encoded'] = encoded_column\n",
    "X_train=X_train.drop(columns=[\"decade\"])\n",
    "\n",
    "\n",
    "# scaling : \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "X_train_transf = RobustScaler().fit(X_train)\n",
    "X_train_transf=X_train_transf.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do some deep learning !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, optimizers\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# transforme le data set X_train, y_train en tenseur\n",
    "#X_train = tf.data.Dataset.from_tensors(X_train_transf)\n",
    "#y_train = tf.data.Dataset.from_tensors(y_train)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_transf,y))\n",
    "# Optionnel: Appliquer des transformations comme le batching\n",
    "#train_dataset = train_dataset.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## si vous avez des couches de pre-traitement\n",
    "#normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "#normalizer.adapt(tensor_dataset)\n",
    "#X_train = normalized(X_train)\n",
    "#y_train = normalized(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m1,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,801</span> (7.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,801\u001b[0m (7.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,801</span> (7.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,801\u001b[0m (7.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# construit le modèle (ici avec des couches denses)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Dense(100, activation=\"relu\",input_shape=(16,)))\n",
    "#model.add(layers.Dense(100, activation=\"relu\"))\n",
    "#model.add(layers.Dense(100, activation=\"relu\"))\n",
    "#model.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.L1(0.03)))\n",
    "#model.add(layers.Dense(100, activation='relu', bias_regularizer=regularizers.L2(0.01)))\n",
    "#model.add(layers.Dense(100, activation=\"relu\", bias_regularizer='l2'))\n",
    "#...\n",
    "\n",
    "# [Optionnel] applique des couches spécifiques (Normalisation, Drop out, Batch Normalisation)\n",
    "#model.add(layers.Dropout(rate=0.2))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# régularisation sur le poids des neurones\n",
    "#reg_l1 = regularizers.L1(0.03)\n",
    "#model.add(layers.Dense(100, activation='relu', kernel_regularizer=reg_l1))\n",
    "\n",
    "# régularisation sur le biais des neurones\n",
    "reg_l2 = regularizers.L2(0.01)\n",
    "\n",
    "# régularsisation sur la sortie de la fonction d'activation\n",
    "#reg_l1_l2 = regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "#model.add(layers.Dense(100, activation='relu', activity_regularizer=reg_l1_l2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "# afficher les paramètres du modèle\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baselearningrate=1\n",
    "#model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    " #             optimizer = tf.keras.optimizers.Adam(learning_rate=baselearningrate/10),\n",
    "  #            metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spécifie loss, optimizer et métrique d'évaluation\n",
    "#model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    " #             optimizer = tf.keras.optimizers.Adam(),\n",
    "  #            metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adamax(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(\n",
    " #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  #  optimizer=tf.keras.optimizers.Adamax(learning_rate=0.002),\n",
    "   # metrics=['accuracy']\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser courbes avec tenserboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Définir le chemin absolu pour log_dir\n",
    "log_dir = r\"C:\\Users\\ContactM2\\Documents\\DESU_LC\\Rochet\\DL\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ContactM2\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:681: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4980 - loss: 239.7962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ContactM2\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:681: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4980 - loss: 239.7322 - val_accuracy: 0.5000 - val_loss: 65.4865\n",
      "Epoch 2/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5085 - loss: 88.4946 - val_accuracy: 0.4995 - val_loss: 93.5664\n",
      "Epoch 3/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5026 - loss: 79.2596 - val_accuracy: 0.4986 - val_loss: 51.7408\n",
      "Epoch 4/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5045 - loss: 77.1745 - val_accuracy: 0.5004 - val_loss: 228.4493\n",
      "Epoch 5/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5107 - loss: 80.2027 - val_accuracy: 0.4998 - val_loss: 118.0872\n",
      "Epoch 6/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5158 - loss: 64.1090 - val_accuracy: 0.5003 - val_loss: 123.4745\n",
      "Epoch 7/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5249 - loss: 52.4501 - val_accuracy: 0.5078 - val_loss: 64.6802\n",
      "Epoch 8/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5195 - loss: 65.9958 - val_accuracy: 0.5040 - val_loss: 14.2336\n",
      "Epoch 9/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5214 - loss: 73.2394 - val_accuracy: 0.4998 - val_loss: 171.2730\n",
      "Epoch 10/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5221 - loss: 66.0193 - val_accuracy: 0.6033 - val_loss: 13.9611\n",
      "Epoch 11/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5330 - loss: 59.8828 - val_accuracy: 0.5093 - val_loss: 80.6487\n",
      "Epoch 12/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 56.5604 - val_accuracy: 0.6276 - val_loss: 11.5881\n",
      "Epoch 13/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5359 - loss: 61.4109 - val_accuracy: 0.5003 - val_loss: 144.6908\n",
      "Epoch 14/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 51.4366 - val_accuracy: 0.5317 - val_loss: 49.7189\n",
      "Epoch 15/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5348 - loss: 49.0869 - val_accuracy: 0.4998 - val_loss: 97.1005\n",
      "Epoch 16/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5333 - loss: 58.8613 - val_accuracy: 0.4925 - val_loss: 31.9376\n",
      "Epoch 17/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5469 - loss: 40.1685 - val_accuracy: 0.5068 - val_loss: 107.5053\n",
      "Epoch 18/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5407 - loss: 58.3419 - val_accuracy: 0.4991 - val_loss: 73.1641\n",
      "Epoch 19/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5380 - loss: 61.8370 - val_accuracy: 0.4970 - val_loss: 53.4910\n",
      "Epoch 20/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - accuracy: 0.5405 - loss: 45.4574 - val_accuracy: 0.5490 - val_loss: 10.5660\n",
      "Epoch 21/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5404 - loss: 52.5889 - val_accuracy: 0.4951 - val_loss: 34.7735\n",
      "Epoch 22/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5433 - loss: 53.2128 - val_accuracy: 0.5000 - val_loss: 243.2839\n",
      "Epoch 23/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5439 - loss: 51.4596 - val_accuracy: 0.6664 - val_loss: 9.0182\n",
      "Epoch 24/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990us/step - accuracy: 0.5346 - loss: 56.0840 - val_accuracy: 0.5012 - val_loss: 189.5436\n",
      "Epoch 25/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5540 - loss: 44.9358 - val_accuracy: 0.5234 - val_loss: 73.7945\n",
      "Epoch 26/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 945us/step - accuracy: 0.5602 - loss: 39.6044 - val_accuracy: 0.5004 - val_loss: 142.3903\n",
      "Epoch 27/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5507 - loss: 52.3544 - val_accuracy: 0.6230 - val_loss: 14.0177\n",
      "Epoch 28/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5563 - loss: 47.3592 - val_accuracy: 0.5686 - val_loss: 28.4863\n",
      "Epoch 29/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5500 - loss: 46.9604 - val_accuracy: 0.5038 - val_loss: 146.7081\n",
      "Epoch 30/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5379 - loss: 58.3850 - val_accuracy: 0.5041 - val_loss: 144.5350\n",
      "Epoch 31/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5551 - loss: 39.7023 - val_accuracy: 0.4940 - val_loss: 28.4150\n",
      "Epoch 32/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5574 - loss: 42.0978 - val_accuracy: 0.5004 - val_loss: 144.7760\n",
      "Epoch 33/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5383 - loss: 50.0571 - val_accuracy: 0.6684 - val_loss: 9.6526\n",
      "Epoch 34/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5691 - loss: 32.6536 - val_accuracy: 0.5004 - val_loss: 127.1053\n",
      "Epoch 35/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5492 - loss: 46.2659 - val_accuracy: 0.5166 - val_loss: 85.7699\n",
      "Epoch 36/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5546 - loss: 50.3849 - val_accuracy: 0.4978 - val_loss: 43.3633\n",
      "Epoch 37/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5476 - loss: 56.0169 - val_accuracy: 0.5281 - val_loss: 63.4389\n",
      "Epoch 38/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5610 - loss: 36.0586 - val_accuracy: 0.4946 - val_loss: 24.2631\n",
      "Epoch 39/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5539 - loss: 46.2579 - val_accuracy: 0.6026 - val_loss: 7.0958\n",
      "Epoch 40/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5630 - loss: 37.5967 - val_accuracy: 0.4984 - val_loss: 52.1088\n",
      "Epoch 41/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5637 - loss: 37.3337 - val_accuracy: 0.4961 - val_loss: 22.0182\n",
      "Epoch 42/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5640 - loss: 33.1646 - val_accuracy: 0.5894 - val_loss: 20.6539\n",
      "Epoch 43/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5722 - loss: 33.8512 - val_accuracy: 0.7080 - val_loss: 4.6597\n",
      "Epoch 44/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5552 - loss: 40.4771 - val_accuracy: 0.5246 - val_loss: 69.2427\n",
      "Epoch 45/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5649 - loss: 35.2968 - val_accuracy: 0.5180 - val_loss: 81.4472\n",
      "Epoch 46/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5524 - loss: 37.4967 - val_accuracy: 0.5008 - val_loss: 194.1217\n",
      "Epoch 47/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5690 - loss: 38.2629 - val_accuracy: 0.4999 - val_loss: 84.7924\n",
      "Epoch 48/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5518 - loss: 45.3707 - val_accuracy: 0.5304 - val_loss: 59.7138\n",
      "Epoch 49/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5723 - loss: 35.5851 - val_accuracy: 0.6412 - val_loss: 12.3015\n",
      "Epoch 50/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 27.5049 - val_accuracy: 0.4981 - val_loss: 38.7943\n",
      "Epoch 51/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5664 - loss: 33.0199 - val_accuracy: 0.5283 - val_loss: 61.4851\n",
      "Epoch 52/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 35.2696 - val_accuracy: 0.5505 - val_loss: 38.8480\n",
      "Epoch 53/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 40.4133 - val_accuracy: 0.4986 - val_loss: 43.1168\n",
      "Epoch 54/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5634 - loss: 38.0300 - val_accuracy: 0.5573 - val_loss: 9.3057\n",
      "Epoch 55/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5616 - loss: 40.6106 - val_accuracy: 0.7161 - val_loss: 5.2777\n",
      "Epoch 56/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 28.2635 - val_accuracy: 0.5765 - val_loss: 25.5942\n",
      "Epoch 57/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5576 - loss: 37.1994 - val_accuracy: 0.5179 - val_loss: 13.1550\n",
      "Epoch 58/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 25.9813 - val_accuracy: 0.4994 - val_loss: 64.6566\n",
      "Epoch 59/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5669 - loss: 29.9176 - val_accuracy: 0.5152 - val_loss: 13.3889\n",
      "Epoch 60/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5684 - loss: 31.5225 - val_accuracy: 0.5802 - val_loss: 23.8950\n",
      "Epoch 61/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 27.9352 - val_accuracy: 0.5352 - val_loss: 53.0111\n",
      "Epoch 62/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5664 - loss: 31.1319 - val_accuracy: 0.4968 - val_loss: 29.6284\n",
      "Epoch 63/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 23.5462 - val_accuracy: 0.5851 - val_loss: 22.1701\n",
      "Epoch 64/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 37.3298 - val_accuracy: 0.5747 - val_loss: 7.7299\n",
      "Epoch 65/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5765 - loss: 30.1993 - val_accuracy: 0.5191 - val_loss: 75.6142\n",
      "Epoch 66/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5737 - loss: 30.8724 - val_accuracy: 0.5104 - val_loss: 99.0070\n",
      "Epoch 67/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5800 - loss: 30.1322 - val_accuracy: 0.5004 - val_loss: 95.6027\n",
      "Epoch 68/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 31.1699 - val_accuracy: 0.6222 - val_loss: 14.5789\n",
      "Epoch 69/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5689 - loss: 31.0170 - val_accuracy: 0.4994 - val_loss: 53.5012\n",
      "Epoch 70/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 27.9911 - val_accuracy: 0.4985 - val_loss: 38.8469\n",
      "Epoch 71/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5586 - loss: 41.1970 - val_accuracy: 0.4994 - val_loss: 59.7812\n",
      "Epoch 72/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 28.8260 - val_accuracy: 0.5851 - val_loss: 21.8330\n",
      "Epoch 73/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 30.3673 - val_accuracy: 0.5032 - val_loss: 136.5194\n",
      "Epoch 74/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 30.3464 - val_accuracy: 0.5411 - val_loss: 45.3493\n",
      "Epoch 75/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5668 - loss: 33.0243 - val_accuracy: 0.7120 - val_loss: 6.2460\n",
      "Epoch 76/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 31.5020 - val_accuracy: 0.4964 - val_loss: 23.8009\n",
      "Epoch 77/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 24.2327 - val_accuracy: 0.7091 - val_loss: 3.9087\n",
      "Epoch 78/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 26.3846 - val_accuracy: 0.6212 - val_loss: 14.3641\n",
      "Epoch 79/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 19.1255 - val_accuracy: 0.4968 - val_loss: 21.1797\n",
      "Epoch 80/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5802 - loss: 26.6661 - val_accuracy: 0.5108 - val_loss: 91.6135\n",
      "Epoch 81/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5656 - loss: 33.4360 - val_accuracy: 0.6990 - val_loss: 7.1711\n",
      "Epoch 82/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 28.1376 - val_accuracy: 0.6926 - val_loss: 7.7799\n",
      "Epoch 83/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 26.3775 - val_accuracy: 0.4974 - val_loss: 19.1124\n",
      "Epoch 84/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 20.6694 - val_accuracy: 0.5986 - val_loss: 17.7111\n",
      "Epoch 85/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 26.9267 - val_accuracy: 0.4970 - val_loss: 19.5890\n",
      "Epoch 86/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 24.4494 - val_accuracy: 0.5004 - val_loss: 98.3559\n",
      "Epoch 87/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5745 - loss: 28.9892 - val_accuracy: 0.4979 - val_loss: 26.2032\n",
      "Epoch 88/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 22.4955 - val_accuracy: 0.5067 - val_loss: 99.6344\n",
      "Epoch 89/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 27.7763 - val_accuracy: 0.4985 - val_loss: 33.2310\n",
      "Epoch 90/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5655 - loss: 33.7260 - val_accuracy: 0.7196 - val_loss: 5.2186\n",
      "Epoch 91/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5665 - loss: 31.7758 - val_accuracy: 0.5768 - val_loss: 23.6462\n",
      "Epoch 92/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 25.7244 - val_accuracy: 0.4991 - val_loss: 39.8435\n",
      "Epoch 93/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 23.7978 - val_accuracy: 0.5004 - val_loss: 114.2894\n",
      "Epoch 94/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 31.0453 - val_accuracy: 0.5291 - val_loss: 9.9866\n",
      "Epoch 95/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 22.9676 - val_accuracy: 0.5735 - val_loss: 25.3956\n",
      "Epoch 96/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 26.5958 - val_accuracy: 0.6030 - val_loss: 16.8482\n",
      "Epoch 97/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 20.7680 - val_accuracy: 0.5095 - val_loss: 91.6352\n",
      "Epoch 98/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 26.3197 - val_accuracy: 0.5869 - val_loss: 20.4460\n",
      "Epoch 99/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 28.5377 - val_accuracy: 0.5088 - val_loss: 91.6470\n",
      "Epoch 100/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 23.8297 - val_accuracy: 0.4995 - val_loss: 42.9081\n",
      "Epoch 101/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 20.4613 - val_accuracy: 0.7324 - val_loss: 3.4337\n",
      "Epoch 102/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 25.9383 - val_accuracy: 0.5329 - val_loss: 49.7123\n",
      "Epoch 103/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5834 - loss: 23.8046 - val_accuracy: 0.5732 - val_loss: 25.2509\n",
      "Epoch 104/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 33.7271 - val_accuracy: 0.6459 - val_loss: 11.3885\n",
      "Epoch 105/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 27.0121 - val_accuracy: 0.5090 - val_loss: 94.2668\n",
      "Epoch 106/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 28.3628 - val_accuracy: 0.4974 - val_loss: 20.2629\n",
      "Epoch 107/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 21.6888 - val_accuracy: 0.5000 - val_loss: 38.4413\n",
      "Epoch 108/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 19.8171 - val_accuracy: 0.4994 - val_loss: 18.1641\n",
      "Epoch 109/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 21.7286 - val_accuracy: 0.5194 - val_loss: 66.1319\n",
      "Epoch 110/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 23.9710 - val_accuracy: 0.7170 - val_loss: 5.4511\n",
      "Epoch 111/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 20.3802 - val_accuracy: 0.5079 - val_loss: 13.6541\n",
      "Epoch 112/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 20.2262 - val_accuracy: 0.5004 - val_loss: 66.8549\n",
      "Epoch 113/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 25.0173 - val_accuracy: 0.4991 - val_loss: 26.9230\n",
      "Epoch 114/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5743 - loss: 31.2063 - val_accuracy: 0.7338 - val_loss: 4.1912\n",
      "Epoch 115/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 21.2712 - val_accuracy: 0.5002 - val_loss: 22.4665\n",
      "Epoch 116/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 22.7732 - val_accuracy: 0.5776 - val_loss: 24.0658\n",
      "Epoch 117/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 26.1880 - val_accuracy: 0.5005 - val_loss: 56.5432\n",
      "Epoch 118/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 24.0124 - val_accuracy: 0.5757 - val_loss: 7.1872\n",
      "Epoch 119/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 22.1348 - val_accuracy: 0.5003 - val_loss: 22.8996\n",
      "Epoch 120/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 23.5254 - val_accuracy: 0.5329 - val_loss: 48.5514\n",
      "Epoch 121/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 21.1155 - val_accuracy: 0.5251 - val_loss: 10.5787\n",
      "Epoch 122/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 20.3466 - val_accuracy: 0.5461 - val_loss: 37.4109\n",
      "Epoch 123/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 19.8070 - val_accuracy: 0.5176 - val_loss: 73.2056\n",
      "Epoch 124/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5880 - loss: 20.3615 - val_accuracy: 0.6672 - val_loss: 10.7591\n",
      "Epoch 125/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 19.5171 - val_accuracy: 0.5002 - val_loss: 24.8799\n",
      "Epoch 126/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 18.4291 - val_accuracy: 0.7299 - val_loss: 3.1110\n",
      "Epoch 127/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 24.7437 - val_accuracy: 0.7335 - val_loss: 4.2382\n",
      "Epoch 128/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 25.3401 - val_accuracy: 0.4992 - val_loss: 24.3468\n",
      "Epoch 129/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 20.0983 - val_accuracy: 0.6171 - val_loss: 5.4222\n",
      "Epoch 130/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 18.7925 - val_accuracy: 0.5002 - val_loss: 35.7898\n",
      "Epoch 131/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5832 - loss: 21.3510 - val_accuracy: 0.6555 - val_loss: 10.2684\n",
      "Epoch 132/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 19.0199 - val_accuracy: 0.7179 - val_loss: 3.5133\n",
      "Epoch 133/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 19.5080 - val_accuracy: 0.5981 - val_loss: 17.9474\n",
      "Epoch 134/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 17.5770 - val_accuracy: 0.5260 - val_loss: 11.2595\n",
      "Epoch 135/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 16.2145 - val_accuracy: 0.7327 - val_loss: 4.4039\n",
      "Epoch 136/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 19.9813 - val_accuracy: 0.5001 - val_loss: 21.7030\n",
      "Epoch 137/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 17.6776 - val_accuracy: 0.5027 - val_loss: 14.4996\n",
      "Epoch 138/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 19.5396 - val_accuracy: 0.5248 - val_loss: 63.6890\n",
      "Epoch 139/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 24.4579 - val_accuracy: 0.5109 - val_loss: 11.7413\n",
      "Epoch 140/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 16.2478 - val_accuracy: 0.7187 - val_loss: 5.8905\n",
      "Epoch 141/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 16.9835 - val_accuracy: 0.5448 - val_loss: 38.1720\n",
      "Epoch 142/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 18.1388 - val_accuracy: 0.5774 - val_loss: 6.2813\n",
      "Epoch 143/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 18.6113 - val_accuracy: 0.5011 - val_loss: 17.2912\n",
      "Epoch 144/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 19.8809 - val_accuracy: 0.5005 - val_loss: 86.8656\n",
      "Epoch 145/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 17.0953 - val_accuracy: 0.7273 - val_loss: 4.2721\n",
      "Epoch 146/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 15.7379 - val_accuracy: 0.6362 - val_loss: 13.1098\n",
      "Epoch 147/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 15.0614 - val_accuracy: 0.5126 - val_loss: 12.7092\n",
      "Epoch 148/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 16.4814 - val_accuracy: 0.6599 - val_loss: 10.0479\n",
      "Epoch 149/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 17.7038 - val_accuracy: 0.5005 - val_loss: 54.4432\n",
      "Epoch 150/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 15.8472 - val_accuracy: 0.6482 - val_loss: 10.4628\n",
      "Epoch 151/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 21.3760 - val_accuracy: 0.5344 - val_loss: 44.9926\n",
      "Epoch 152/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 19.3874 - val_accuracy: 0.5045 - val_loss: 12.2371\n",
      "Epoch 153/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 18.1445 - val_accuracy: 0.5003 - val_loss: 22.6334\n",
      "Epoch 154/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5926 - loss: 20.0187 - val_accuracy: 0.5003 - val_loss: 22.1328\n",
      "Epoch 155/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 19.0860 - val_accuracy: 0.5583 - val_loss: 30.4793\n",
      "Epoch 156/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6052 - loss: 15.6389 - val_accuracy: 0.5005 - val_loss: 42.1020\n",
      "Epoch 157/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 15.5327 - val_accuracy: 0.5019 - val_loss: 141.0204\n",
      "Epoch 158/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5918 - loss: 19.4725 - val_accuracy: 0.5005 - val_loss: 53.5940\n",
      "Epoch 159/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5989 - loss: 15.1333 - val_accuracy: 0.6644 - val_loss: 9.8432\n",
      "Epoch 160/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5895 - loss: 19.6581 - val_accuracy: 0.6969 - val_loss: 7.4866\n",
      "Epoch 161/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 17.2257 - val_accuracy: 0.5005 - val_loss: 15.8150\n",
      "Epoch 162/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6031 - loss: 17.0456 - val_accuracy: 0.7240 - val_loss: 3.3556\n",
      "Epoch 163/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6057 - loss: 15.1796 - val_accuracy: 0.6613 - val_loss: 9.8721\n",
      "Epoch 164/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6026 - loss: 17.7984 - val_accuracy: 0.7048 - val_loss: 2.6751\n",
      "Epoch 165/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6079 - loss: 14.3595 - val_accuracy: 0.5585 - val_loss: 28.4329\n",
      "Epoch 166/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6028 - loss: 15.9636 - val_accuracy: 0.5320 - val_loss: 43.9797\n",
      "Epoch 167/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 14.7451 - val_accuracy: 0.7204 - val_loss: 5.3601\n",
      "Epoch 168/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 17.4571 - val_accuracy: 0.5813 - val_loss: 20.8140\n",
      "Epoch 169/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 15.9085 - val_accuracy: 0.7011 - val_loss: 5.6026\n",
      "Epoch 170/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 15.3697 - val_accuracy: 0.5005 - val_loss: 43.0081\n",
      "Epoch 171/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 16.0581 - val_accuracy: 0.6855 - val_loss: 8.3209\n",
      "Epoch 172/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 18.0983 - val_accuracy: 0.5178 - val_loss: 64.0239\n",
      "Epoch 173/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 16.2739 - val_accuracy: 0.5821 - val_loss: 22.1139\n",
      "Epoch 174/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 16.4819 - val_accuracy: 0.7195 - val_loss: 4.8196\n",
      "Epoch 175/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 19.6611 - val_accuracy: 0.6380 - val_loss: 11.2558\n",
      "Epoch 176/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 14.7854 - val_accuracy: 0.5005 - val_loss: 32.3399\n",
      "Epoch 177/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 15.0077 - val_accuracy: 0.5624 - val_loss: 26.6460\n",
      "Epoch 178/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 14.2868 - val_accuracy: 0.7317 - val_loss: 3.7698\n",
      "Epoch 179/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 13.1465 - val_accuracy: 0.5179 - val_loss: 63.2414\n",
      "Epoch 180/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 15.1088 - val_accuracy: 0.5285 - val_loss: 49.1577\n",
      "Epoch 181/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 16.2971 - val_accuracy: 0.5822 - val_loss: 20.0674\n",
      "Epoch 182/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 14.6902 - val_accuracy: 0.5005 - val_loss: 28.0134\n",
      "Epoch 183/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 15.6380 - val_accuracy: 0.7049 - val_loss: 6.2647\n",
      "Epoch 184/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 12.1953 - val_accuracy: 0.5201 - val_loss: 57.2129\n",
      "Epoch 185/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6048 - loss: 16.3149 - val_accuracy: 0.5005 - val_loss: 20.9770\n",
      "Epoch 186/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6193 - loss: 11.3446 - val_accuracy: 0.6839 - val_loss: 7.6941\n",
      "Epoch 187/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6025 - loss: 17.8805 - val_accuracy: 0.5601 - val_loss: 28.0033\n",
      "Epoch 188/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 15.1449 - val_accuracy: 0.5320 - val_loss: 44.4420\n",
      "Epoch 189/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 15.2178 - val_accuracy: 0.5005 - val_loss: 22.3952\n",
      "Epoch 190/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 16.0293 - val_accuracy: 0.7039 - val_loss: 5.9456\n",
      "Epoch 191/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 11.0301 - val_accuracy: 0.7260 - val_loss: 4.5003\n",
      "Epoch 192/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6337 - loss: 10.4995 - val_accuracy: 0.5209 - val_loss: 53.4901\n",
      "Epoch 193/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 13.2250 - val_accuracy: 0.6063 - val_loss: 15.5148\n",
      "Epoch 194/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 12.3599 - val_accuracy: 0.7371 - val_loss: 2.5430\n",
      "Epoch 195/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 12.3846 - val_accuracy: 0.7240 - val_loss: 4.5788\n",
      "Epoch 196/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 14.5255 - val_accuracy: 0.5005 - val_loss: 35.2125\n",
      "Epoch 197/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 14.2717 - val_accuracy: 0.6742 - val_loss: 8.5479\n",
      "Epoch 198/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 14.7954 - val_accuracy: 0.5735 - val_loss: 21.8177\n",
      "Epoch 199/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 11.5046 - val_accuracy: 0.5857 - val_loss: 19.0880\n",
      "Epoch 200/200\n",
      "\u001b[1m1799/1799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6096 - loss: 13.3909 - val_accuracy: 0.5010 - val_loss: 15.6120\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y,\n",
    "          validation_split=0.3,\n",
    "          batch_size=16,\n",
    "          epochs=200,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pour visualiser les courbes, lancer tensorboard depuis le terminal :\n",
    "# tensorboard --logdir \"C:\\Users\\ContactM2\\Documents\\DESU_LC\\Rochet\\DL\\logs\"\n",
    "# tensorboard --logdir \"C:\\Users\\ContactM2\\Documents\\DESU_LC\\Rochet\\DL\\20240713-003002\"\n",
    "# Puis dans le navigateur : http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "model.save('model_spotify_test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recharger le modèle\n",
    "loaded_model = tf.keras.models.load_model('model_spotify_test.keras')\n",
    "\n",
    "# Vérifier que le modèle a été correctement chargé\n",
    "loaded_model.summary()\n",
    "\n",
    "# Optionnel : Réévaluer le modèle sur les données d'entraînement pour vérifier qu'il fonctionne correctement\n",
    "loaded_model.evaluate(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
